{
  "timestamp": "2025-11-01 12:28:53",
  "execution_time": 104.83765172958374,
  "summary": {
    "total_test_categories": 2,
    "passed_categories": 0,
    "failed_categories": 2,
    "success_rate": 0.0
  },
  "categories": {
    "unit_tests": {
      "exit_code": 1,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.11.7, pytest-7.4.3, pluggy-1.6.0\nrootdir: R:\\ARTHEN-LANG\\tests\nconfigfile: pytest.ini\nplugins: anyio-3.7.1, dash-3.2.0, cov-7.0.0, html-4.1.1, json-report-1.5.0, metadata-3.1.1, xdist-3.8.0, web3-6.5.0\ncollected 29 items\n\ntests\\test_arthen_comprehensive.py FF.FF..F.F.FF..FFFFFFF...FFF.         [100%]\n\n================================== FAILURES ===================================\n__________ TestARTHENCompilerArchitecture.test_ai_code_optimization ___________\n\nself = <test_arthen_comprehensive.TestARTHENCompilerArchitecture testMethod=test_ai_code_optimization>\n\n    def test_ai_code_optimization(self):\n        \"\"\"Test AI-driven code optimization\"\"\"\n        optimizer = AICodeOptimizer()\n    \n        mock_ast = {\n            'type': 'Program',\n            'body': [{\n                'type': 'Function',\n                'name': 'test_function',\n                'parameters': [],\n                'body': []\n            }]\n        }\n    \n        optimized_ast = optimizer.optimize(mock_ast, BlockchainTarget.ETHEREUM)\n    \n        self.assertIsInstance(optimized_ast, dict)\n>       self.assertIn('optimization_metadata', optimized_ast)\nE       AssertionError: 'optimization_metadata' not found in {'type': 'Program', 'body': [{'type': 'Function', 'name': 'test_function', 'parameters': [], 'body': []}]}\n\ntests\\test_arthen_comprehensive.py:164: AssertionError\n___________ TestARTHENCompilerArchitecture.test_compilation_config ____________\n\nself = <test_arthen_comprehensive.TestARTHENCompilerArchitecture testMethod=test_compilation_config>\n\n    def test_compilation_config(self):\n        \"\"\"Test compilation configuration\"\"\"\n>       config = CompilationConfig(\n            target_blockchain=BlockchainTarget.ETHEREUM,\n            optimization_level=\"maximum\",\n            ai_enhancement=True,\n            security_analysis=True,\n            output_directory=\"./output\"\n        )\nE       TypeError: CompilationConfig.__init__() got an unexpected keyword argument 'output_directory'\n\ntests\\test_arthen_comprehensive.py:82: TypeError\n________ TestARTHENCompilerArchitecture.test_full_compilation_pipeline ________\n\nself = <test_arthen_comprehensive.TestARTHENCompilerArchitecture testMethod=test_full_compilation_pipeline>\n\n    def test_full_compilation_pipeline(self):\n        \"\"\"Test complete compilation pipeline\"\"\"\n>       config = CompilationConfig(\n            target=BlockchainTarget.ETHEREUM,\n            optimization_level=\"maximum\",\n            ai_enhancement=True,\n            security_analysis=True\n        )\nE       TypeError: CompilationConfig.__init__() got an unexpected keyword argument 'target'\n\ntests\\test_arthen_comprehensive.py:189: TypeError\n___________ TestARTHENCompilerArchitecture.test_lexer_tokenization ____________\n\nself = <test_arthen_comprehensive.TestARTHENCompilerArchitecture testMethod=test_lexer_tokenization>\n\n    def test_lexer_tokenization(self):\n        \"\"\"Test AI-optimized lexer tokenization\"\"\"\n        lexer = AIOptimizedLexer()\n        tokens = lexer.tokenize(self.sample_arthen_code)\n    \n        self.assertIsInstance(tokens, list)\n        self.assertGreater(len(tokens), 0)\n    \n        # Check for ARTHEN-specific tokens\n        token_types = [token.get('type') for token in tokens]\n>       self.assertIn('AI_SYMBOL', token_types)\nE       AssertionError: 'AI_SYMBOL' not found in ['DELTA_CONTRACT', 'ML_CONSENSUS', 'ML_CONSENSUS', 'ML_PRIMITIVE']\n\ntests\\test_arthen_comprehensive.py:105: AssertionError\n__________ TestARTHENCompilerArchitecture.test_parser_ast_generation __________\n\nself = <test_arthen_comprehensive.TestARTHENCompilerArchitecture testMethod=test_parser_ast_generation>\n\n    def test_parser_ast_generation(self):\n        \"\"\"Test transformer-based parser AST generation\"\"\"\n        parser = TransformerParser()\n        lexer = AIOptimizedLexer()\n    \n        tokens = lexer.tokenize(self.sample_arthen_code)\n        ast = parser.parse(tokens)\n    \n        self.assertIsInstance(ast, dict)\n        self.assertIn('type', ast)\n>       self.assertEqual(ast['type'], 'Program')\nE       AssertionError: 'ARTHEN_PROGRAM' != 'Program'\nE       - ARTHEN_PROGRAM\nE       + Program\n\ntests\\test_arthen_comprehensive.py:118: AssertionError\n__________ TestARTHENStandardLibrary.test_ai_throughput_enhancement ___________\n\nself = <test_arthen_comprehensive.TestARTHENStandardLibrary testMethod=test_ai_throughput_enhancement>\n\n    def test_ai_throughput_enhancement(self):\n        \"\"\"Test AI-powered throughput enhancement\"\"\"\n        network_metrics = {\n            'current_throughput': 800,\n            'target_throughput': 1500,\n            'latency': 120,\n            'load': 0.7\n        }\n    \n        result = self.stdlib.ai_throughput_enhancement(network_metrics)\n    \n        self.assertIsInstance(result, dict)\n>       self.assertIn('optimization_applied', result)\nE       AssertionError: 'optimization_applied' not found in {'current_throughput': 0, 'enhanced_throughput': 1450.0, 'improvement_percentage': 44.99999999999999, 'bottlenecks_resolved': 2, 'enhancement_applied': True, 'enhancement_confidence': 0.91}\n\ntests\\test_arthen_comprehensive.py:476: AssertionError\n__________ TestARTHENStandardLibrary.test_intelligent_bridge_routing __________\n\nself = <test_arthen_comprehensive.TestARTHENStandardLibrary testMethod=test_intelligent_bridge_routing>\n\n    def test_intelligent_bridge_routing(self):\n        \"\"\"Test AI-powered cross-chain bridge routing\"\"\"\n        result = self.stdlib.intelligent_bridge_routing(\n            BlockchainPlatform.ETHEREUM,\n            BlockchainPlatform.SOLANA,\n            100.0\n        )\n    \n        self.assertIsInstance(result, dict)\n>       self.assertIn('optimal_route', result)\nE       AssertionError: 'optimal_route' not found in {'source_chain': 'ethereum', 'destination_chain': 'solana', 'optimal_path': {'source': 'ethereum', 'destination': 'solana', 'intermediate_chains': ['cosmos'], 'path_efficiency': 0.92, 'security_rating': 0.95}, 'estimated_fees': 0.001275, 'security_verified': True, 'routing_confidence': 0.94, 'estimated_time': 45.0}\n\ntests\\test_arthen_comprehensive.py:342: AssertionError\n_____________ TestARTHENStandardLibrary.test_intelligent_scaling ______________\n\nself = <test_arthen_comprehensive.TestARTHENStandardLibrary testMethod=test_intelligent_scaling>\n\n    def test_intelligent_scaling(self):\n        \"\"\"Test intelligent scaling based on demand prediction\"\"\"\n        demand_metrics = {\n            'current_demand': 75.0,\n            'predicted_demand': 120.0,\n            'capacity_utilization': 0.8,\n            'response_time': 150.0\n        }\n    \n        result = self.stdlib.intelligent_scaling(demand_metrics)\n    \n        self.assertIsInstance(result, dict)\n>       self.assertIn('scaling_recommendation', result)\nE       AssertionError: 'scaling_recommendation' not found in {'current_demand': 0, 'predicted_demand': 60.0, 'scaling_factor': 1.0, 'scaling_executed': True, 'new_capacity': 100.0, 'scaling_confidence': 0.88}\n\ntests\\test_arthen_comprehensive.py:508: AssertionError\n__________ TestARTHENStandardLibrary.test_ml_vulnerability_detection __________\n\nself = <test_arthen_comprehensive.TestARTHENStandardLibrary testMethod=test_ml_vulnerability_detection>\n\n    def test_ml_vulnerability_detection(self):\n        \"\"\"Test ML-powered vulnerability detection\"\"\"\n        sample_contract = \"\"\"\n        function transfer(address to, uint256 amount) public {\n            require(balances[msg.sender] >= amount);\n            balances[msg.sender] -= amount;\n            balances[to] += amount;\n        }\n        \"\"\"\n    \n>       result = self.stdlib.ml_vulnerability_detection(sample_contract)\nE       TypeError: ARTHENCompleteStandardLibrary.ml_vulnerability_detection() missing 1 required positional argument: 'platform'\n\ntests\\test_arthen_comprehensive.py:457: TypeError\n____________ TestARTHENStandardLibrary.test_neural_load_balancing _____________\n\nself = <test_arthen_comprehensive.TestARTHENStandardLibrary testMethod=test_neural_load_balancing>\n\n    def test_neural_load_balancing(self):\n        \"\"\"Test neural network-based load balancing\"\"\"\n        node_loads = {\n            'node_1': 0.8,\n            'node_2': 0.6,\n            'node_3': 0.9,\n            'node_4': 0.4\n        }\n    \n        result = self.stdlib.neural_load_balancing(node_loads)\n    \n        self.assertIsInstance(result, dict)\n>       self.assertIn('load_distribution', result)\nE       AssertionError: 'load_distribution' not found in {'nodes_balanced': 4, 'load_variance_before': 0.036875000000000005, 'load_variance_after': 0.02, 'balancing_improvement': 80.0, 'optimal_distribution': {'node_1': 0.25, 'node_2': 0.25, 'node_3': 0.25, 'node_4': 0.25}, 'balancing_confidence': 0.94}\n\ntests\\test_arthen_comprehensive.py:492: AssertionError\n___________ TestARTHENStandardLibrary.test_neural_network_consensus ___________\n\nself = <test_arthen_comprehensive.TestARTHENStandardLibrary testMethod=test_neural_network_consensus>\n\n    def test_neural_network_consensus(self):\n        \"\"\"Test neural network-based consensus\"\"\"\n        # Create sample network data\n        network_data = np.random.rand(10, 5).astype(np.float32)\n    \n>       result = self.stdlib.neural_network_consensus(network_data)\n\ntests\\test_arthen_comprehensive.py:325: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nstdlib\\arthen_stdlib_implementation.py:1597: in neural_network_consensus\n    consensus_output = self.ml_consensus.neural_analyzer(data_tensor.unsqueeze(0))\nC:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773: in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\nC:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784: in _call_impl\n    return forward_call(*args, **kwargs)\nstdlib\\arthen_stdlib_implementation.py:244: in forward\n    return self.network(network_state)\nC:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773: in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\nC:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784: in _call_impl\n    return forward_call(*args, **kwargs)\nC:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\container.py:244: in forward\n    input = module(input)\nC:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773: in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\nC:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784: in _call_impl\n    return forward_call(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Linear(in_features=7, out_features=128, bias=True)\ninput = tensor([[[0.9370, 0.1946, 0.0478, 0.7205, 0.7490],\n         [0.3263, 0.8091, 0.2198, 0.0257, 0.2402],\n         [0.2467....6641, 0.6383],\n         [0.4663, 0.5570, 0.2796, 0.5254, 0.9518],\n         [0.7081, 0.6245, 0.0062, 0.1083, 0.6074]]])\n\n    def forward(self, input: Tensor) -> Tensor:\n>       return F.linear(input, self.weight, self.bias)\nE       RuntimeError: mat1 and mat2 shapes cannot be multiplied (10x5 and 7x128)\n\nC:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125: RuntimeError\n_____________ TestARTHENStandardLibrary.test_stdlib_consensus_ai ______________\n\nself = <test_arthen_comprehensive.TestARTHENStandardLibrary testMethod=test_stdlib_consensus_ai>\n\n    def test_stdlib_consensus_ai(self):\n        \"\"\"Test standard library consensus AI functions\"\"\"\n        # Test harmony_all_types function\n        network_state = NetworkState(\n            throughput=1000.0,\n            latency=50.0,\n            security_score=0.9,\n            decentralization_index=0.8,\n            node_count=1000,\n            transaction_volume=10000.0,\n            consensus_efficiency=0.85\n        )\n    \n        result = self.stdlib.harmony_all_types(network_state)\n        self.assertIsInstance(result, AIConfidence)\n        self.assertGreater(result.confidence, 0.0)\n        self.assertLessEqual(result.confidence, 1.0)\n    \n        # Test additional consensus AI functions\n        validators = [{'id': 'validator_1', 'uptime': 0.99, 'stake': 1000000}]\n        selection_result = self.stdlib.ml_validator_selection(validators, {'load': 0.5})\n        self.assertIsInstance(selection_result, dict)\n        self.assertIn('selected_validators', selection_result)\n    \n        # Test fork resolution\n        fork_data = {\n            'block_height': 100000,\n            'chains': [{'id': 'chain_a', 'cumulative_difficulty': 1500000}],\n            'stake_weights': {'chain_a': 0.6},\n            'node_support': {'chain_a': 120}\n        }\n    \n        fork_result = self.stdlib.ai_fork_resolution(fork_data)\n        self.assertIsInstance(fork_result, dict)\n        self.assertIn('resolution_method', fork_result)\n    \n        # Test neural network consensus\n        consensus_data = np.random.rand(10, 5).astype(np.float32)\n>       neural_result = self.stdlib.neural_network_consensus(consensus_data)\n\ntests\\test_arthen_comprehensive.py:296: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nstdlib\\arthen_stdlib_implementation.py:1597: in neural_network_consensus\n    consensus_output = self.ml_consensus.neural_analyzer(data_tensor.unsqueeze(0))\nC:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773: in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\nC:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784: in _call_impl\n    return forward_call(*args, **kwargs)\nstdlib\\arthen_stdlib_implementation.py:244: in forward\n    return self.network(network_state)\nC:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773: in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\nC:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784: in _call_impl\n    return forward_call(*args, **kwargs)\nC:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\container.py:244: in forward\n    input = module(input)\nC:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773: in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\nC:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784: in _call_impl\n    return forward_call(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Linear(in_features=7, out_features=128, bias=True)\ninput = tensor([[[0.9778, 0.8761, 0.2674, 0.9169, 0.7372],\n         [0.9324, 0.1312, 0.4581, 0.8363, 0.2201],\n         [0.7533....7684, 0.5182],\n         [0.2398, 0.0440, 0.0606, 0.8300, 0.2181],\n         [0.7128, 0.7207, 0.2167, 0.4634, 0.0029]]])\n\n    def forward(self, input: Tensor) -> Tensor:\n>       return F.linear(input, self.weight, self.bias)\nE       RuntimeError: mat1 and mat2 shapes cannot be multiplied (10x5 and 7x128)\n\nC:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125: RuntimeError\n_____________ TestARTHENStandardLibrary.test_stdlib_crosschain_ai _____________\n\nself = <test_arthen_comprehensive.TestARTHENStandardLibrary testMethod=test_stdlib_crosschain_ai>\n\n    def test_stdlib_crosschain_ai(self):\n        \"\"\"Test standard library cross-chain AI functions\"\"\"\n        # Test intelligent_bridge_routing\n        bridge_request = {\n            'source_chain': 'ethereum',\n            'target_chain': 'solana',\n            'amount': 1000.0,\n            'token_type': 'ERC20'\n        }\n    \n>       routing_result = self.stdlib.intelligent_bridge_routing(bridge_request)\nE       TypeError: ARTHENCompleteStandardLibrary.intelligent_bridge_routing() missing 2 required positional arguments: 'dest_chain' and 'asset_amount'\n\ntests\\test_arthen_comprehensive.py:357: TypeError\n____________ TestARTHENStandardLibrary.test_stdlib_performance_ai _____________\n\nself = <test_arthen_comprehensive.TestARTHENStandardLibrary testMethod=test_stdlib_performance_ai>\n\n    def test_stdlib_performance_ai(self):\n        \"\"\"Test standard library performance AI functions\"\"\"\n        # Test ml_gas_optimization\n        contract_code = {\n            'functions': [\n                {'name': 'transfer', 'gas_estimate': 21000},\n                {'name': 'approve', 'gas_estimate': 46000}\n            ],\n            'storage_operations': 5,\n            'computation_complexity': 'medium'\n        }\n    \n>       gas_result = self.stdlib.ml_gas_optimization(contract_code)\nE       TypeError: ARTHENCompleteStandardLibrary.ml_gas_optimization() missing 1 required positional argument: 'platform'\n\ntests\\test_arthen_comprehensive.py:406: TypeError\n__________________ TestARTHENAISyntax.test_ai_symbol_parsing __________________\n\nself = <test_arthen_comprehensive.TestARTHENAISyntax testMethod=test_ai_symbol_parsing>\n\n    def test_ai_symbol_parsing(self):\n        \"\"\"Test AI symbol parsing (\\u2206\\u2207\\u27e8\\u27e9)\"\"\"\n        lexer = AIOptimizedLexer()\n    \n        ai_syntax_samples = [\n            \"\\u2206\\u2207\\u27e8blockchain_contract\\u27e9\",\n            \"\\u2206ml_consensus: harmony_all_types\",\n            \"\\u2207neural_network.train(validator_behavior)\",\n            \"\\u2206tensor\\u27e8u256\\u27e9 blockchain_state\"\n        ]\n    \n        for sample in ai_syntax_samples:\n            tokens = lexer.tokenize(sample)\n            self.assertGreater(len(tokens), 0)\n    \n            # Check for AI-specific token types\n            token_types = [token.get('type') for token in tokens]\n>           self.assertTrue(any('AI_' in token_type for token_type in token_types))\nE           AssertionError: False is not true\n\ntests\\test_arthen_comprehensive.py:533: AssertionError\n______________ TestARTHENIntegration.test_end_to_end_compilation ______________\n\nself = <test_arthen_comprehensive.TestARTHENIntegration testMethod=test_end_to_end_compilation>\n\n    def test_end_to_end_compilation(self):\n        \"\"\"Test end-to-end compilation with standard library integration\"\"\"\n        arthen_code = \"\"\"\n        \\u2206\\u2207\\u27e8ai_defi_contract\\u27e9 {\n            \\u2206ml_consensus: harmony_all_types,\n            \\u2206target_chains: [ethereum, solana, cosmos],\n            \\u2206ai_optimization_level: maximum\n        }\n    \n        \\u2207\\u27e8liquidity_pool\\u27e9 {\n            \\u2206ml_price_oracle\\u27e8asset_pair\\u27e9 -> \\u2206price_prediction {\n                \\u2207neural_network.predict(market_data);\n                \\u2207ai_optimizer.calculate(optimal_price);\n                return \\u2206harmonized_price;\n            }\n    \n            \\u2206ai_risk_assessment\\u27e8pool_state\\u27e9 -> \\u2206risk_score {\n                \\u2207ml_analyzer.evaluate(liquidity_metrics);\n                \\u2207security_ai.scan(potential_vulnerabilities);\n                return \\u2206comprehensive_risk_analysis;\n            }\n        }\n        \"\"\"\n    \n>       config = CompilationConfig(\n            target=BlockchainTarget.ETHEREUM,\n            optimization_level=\"maximum\",\n            ai_enhancement=True,\n            security_analysis=True\n        )\nE       TypeError: CompilationConfig.__init__() got an unexpected keyword argument 'target'\n\ntests\\test_arthen_comprehensive.py:603: TypeError\n_____________ TestARTHENIntegration.test_multi_chain_compilation ______________\n\nself = <test_arthen_comprehensive.TestARTHENIntegration testMethod=test_multi_chain_compilation>\n\n    def test_multi_chain_compilation(self):\n        \"\"\"Test compilation for multiple blockchain targets\"\"\"\n        simple_contract = \"\"\"\n        \\u2206\\u2207\\u27e8multi_chain_contract\\u27e9 {\n            \\u2206ml_consensus: harmony_all_types,\n            \\u2206ai_optimization_level: maximum\n        }\n        \"\"\"\n    \n        targets = [\n            BlockchainTarget.ETHEREUM,\n            BlockchainTarget.SOLANA,\n            BlockchainTarget.COSMOS,\n            BlockchainTarget.POLKADOT\n        ]\n    \n        for target in targets:\n>           config = CompilationConfig(\n                target=target,\n                optimization_level=\"maximum\",\n                ai_enhancement=True\n            )\nE           TypeError: CompilationConfig.__init__() got an unexpected keyword argument 'target'\n\ntests\\test_arthen_comprehensive.py:654: TypeError\n_____________ TestARTHENPerformance.test_compilation_performance ______________\n\nself = <test_arthen_comprehensive.TestARTHENPerformance testMethod=test_compilation_performance>\n\n    def test_compilation_performance(self):\n        \"\"\"Test compilation performance with large code\"\"\"\n        # Generate large ARTHEN code for performance testing\n        large_code = self._generate_large_arthen_code(100)  # 100 functions\n    \n>       config = CompilationConfig(\n            target=BlockchainTarget.ETHEREUM,\n            optimization_level=\"maximum\"\n        )\nE       TypeError: CompilationConfig.__init__() got an unexpected keyword argument 'target'\n\ntests\\test_arthen_comprehensive.py:674: TypeError\n============================== warnings summary ===============================\ntest_arthen_comprehensive.py: 12 warnings\n  C:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n    warnings.warn(\n\ntest_arthen_comprehensive.py::TestARTHENCompilerArchitecture::test_parser_ast_generation\n  R:\\ARTHEN-LANG\\tests\\..\\compiler\\arthen_compiler_architecture.py:196: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n  Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\generated\\python_variable_methods.cpp:836.)\n    'confidence_score': float(pattern_strength)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n--------------------------------- JSON report ---------------------------------\nreport saved to: R:\\ARTHEN-LANG\\tests\\reports\\unit_tests.json\n=============================== tests coverage ================================\n_______________ coverage: platform win32, python 3.11.7-final-0 _______________\n\nName                                       Stmts   Miss  Cover   Missing\n------------------------------------------------------------------------\ncompiler\\arthen_compiler.py                  142    142     0%   13-264\ncompiler\\arthen_compiler_architecture.py     747    439    41%   111, 126-129, 149, 294-295, 448, 507-528, 552, 558-569, 573-584, 588-616, 620-627, 647, 653, 659-679, 683-692, 696-703, 710-723, 727-740, 744-765, 769-776, 783-791, 795-825, 829-855, 859-866, 870-877, 884-892, 896-926, 930-955, 959-966, 970-977, 984-999, 1003-1010, 1014-1043, 1047-1054, 1058-1065, 1072-1087, 1091-1106, 1110-1120, 1124-1131, 1147-1164, 1196-1207, 1221-1240, 1244, 1262-1267, 1273-1283, 1287-1297, 1301-1311, 1315-1325, 1329-1339, 1343-1353, 1364-1369, 1375-1394, 1399-1402, 1407-1410, 1462-1496, 1525, 1534, 1548-1551, 1569-1581, 1599-1610, 1619, 1622, 1648-1651, 1656-1659, 1664-1667, 1672-1675, 1679-1681, 1685, 1689-1692, 1697-1732\nstdlib\\arthen_stdlib_implementation.py       634    213    66%   108-131, 144-165, 178-192, 204-217, 221, 274-281, 341-359, 364-367, 400-407, 413-422, 428-432, 467-468, 476-477, 506-515, 524-533, 541-543, 552-561, 565, 583-590, 598-599, 604-606, 611, 619-620, 624-626, 630, 637-638, 642, 654-655, 659, 671, 675, 707, 768-776, 788-796, 808-816, 868-876, 888-896, 909-917, 929, 953-961, 1045-1046, 1072-1081, 1085, 1094, 1106-1107, 1115-1120, 1128, 1136-1139, 1156, 1176, 1195, 1200, 1209-1230, 1234-1247, 1251, 1262, 1272-1283, 1287, 1304-1308, 1317-1320, 1329, 1337, 1345-1349, 1358-1365, 1465, 1598-1603, 1623, 1627, 1631, 1644, 1648, 1652, 1661, 1702\n------------------------------------------------------------------------\nTOTAL                                       1523    794    48%\nCoverage HTML written to dir htmlcov\n- Generated html report: file:///R:/ARTHEN-LANG/tests/reports/unit_tests.html -\n=========================== short test summary info ===========================\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENCompilerArchitecture::test_ai_code_optimization\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENCompilerArchitecture::test_compilation_config\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENCompilerArchitecture::test_full_compilation_pipeline\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENCompilerArchitecture::test_lexer_tokenization\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENCompilerArchitecture::test_parser_ast_generation\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENStandardLibrary::test_ai_throughput_enhancement\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENStandardLibrary::test_intelligent_bridge_routing\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENStandardLibrary::test_intelligent_scaling\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENStandardLibrary::test_ml_vulnerability_detection\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENStandardLibrary::test_neural_load_balancing\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENStandardLibrary::test_neural_network_consensus\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENStandardLibrary::test_stdlib_consensus_ai\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENStandardLibrary::test_stdlib_crosschain_ai\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENStandardLibrary::test_stdlib_performance_ai\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENAISyntax::test_ai_symbol_parsing\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENIntegration::test_end_to_end_compilation\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENIntegration::test_multi_chain_compilation\nFAILED tests\\test_arthen_comprehensive.py::TestARTHENPerformance::test_compilation_performance\n============ 18 failed, 11 passed, 13 warnings in 79.67s (0:01:19) ============\n",
      "stderr": "C:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\eth_keyfile\\__init__.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  import pkg_resources\nC:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\coverage\\report_core.py:107: CoverageWarning: Couldn't parse Python file 'R:\\ARTHEN-LANG\\parser\\ai_native_parser.py' (couldnt-parse); see https://coverage.readthedocs.io/en/7.11.0/messages.html#warning-couldnt-parse\n  coverage._warn(msg, slug=\"couldnt-parse\")\n",
      "success": false
    },
    "integration_tests": {
      "exit_code": 5,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.11.7, pytest-7.4.3, pluggy-1.6.0\nrootdir: R:\\ARTHEN-LANG\\tests\nconfigfile: pytest.ini\nplugins: anyio-3.7.1, dash-3.2.0, cov-7.0.0, html-4.1.1, json-report-1.5.0, metadata-3.1.1, xdist-3.8.0, web3-6.5.0\ncollected 29 items / 29 deselected / 0 selected\n\n--------------------------------- JSON report ---------------------------------\nreport saved to: R:\\ARTHEN-LANG\\tests\\reports\\integration_tests.json\n- Generated html report: file:///R:/ARTHEN-LANG/tests/reports/integration_tests.html -\n=========================== 29 deselected in 7.69s ============================\n",
      "stderr": "C:\\Users\\l3unu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\eth_keyfile\\__init__.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  import pkg_resources\n",
      "success": false
    }
  },
  "environment": {
    "python_version": "3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]",
    "platform": "win32",
    "project_root": "R:\\ARTHEN-LANG"
  },
  "arthen_info": {
    "language_version": "2.0.0",
    "compiler_version": "2.0.0",
    "stdlib_version": "2.0.0"
  }
}